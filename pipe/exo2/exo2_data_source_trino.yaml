---
pipeline:
  name: exo2_data_source_trino
transform:
  image: us-central1-docker.pkg.dev/neon-shared-service/neonscience/neon-is-data-src-trino:v2.3.0
  cmd:
  - sh
  - "-c"
  - |-
    /bin/bash <<'EOF'
    # Use bash-scrict mode. See http://redsymbol.net/articles/unofficial-bash-strict-mode/
    set -euo pipefail
    IFS=$'\n\t'
    
    # Refresh interim directories with each datum (otherwise they persist and cause probs)
    interimDir="/tmp/interimData"
    rm -rf $interimDir
    
    # Get today's date for evaluating kafka data retention period
    date_today=$(date -u +%Y-%m-%d)
    kafka_min_date=$(date -u -d "$KAFKA_RETENTION_DAYS days ago" +%Y-%m-%d)
    
    # Run first module - data_source_site (pull data from database by site)
    # Split data source path
    for path in $(find -L $import_trigger -type f); do
      echo "Processing $path"
      p=${path#/pfs}
      IFS="/"; arr=($p); unset IFS;
      year=${arr[3]}
      month=${arr[4]}
      day=${arr[5]}
      site=${arr[6]}
      type=$(echo $site | cut -f 2 -d "." --only-delimited); # Extract the "kafka" from site.kafka if present
      if [ "$type" = "kafka" ] && [ $(date -u +%s -d $year-$month-$day) -lt $(date -u +%s -d $kafka_min_date) ]
      then
        site=$(echo $site | cut -f 1 -d "." --only-delimited); # Extract the site from site.kafka.
        echo "$year/$month/$day for $site is indicated to be streaming from Kafka but has passed the Kafka retention period ($KAFKA_RETENTION_DAYS days)."
      elif [ "$type" = "kafka" ]
      then
        echo "$year/$month/$day/$site is indicated to be streaming from Kafka. Skipping..."
        continue
      fi
      echo "Extracting data from Trino for $year/$month/$day/$site"
      export GEN_DATE=$year-$month-$day
      export GEN_SITE_NAME=$site
      export REQUESTS_CA_BUNDLE=/etc/pki/tls/cert.pem
      
      # exo2
      export SOURCE_TYPE=$SOURCE_TYPE_1
      export GEN_YAML_CONF=$GEN_YAML_CONF_1
      export GEN_SCHEMA_FILE=$GEN_SCHEMA_FILE_1
      export GEN_OUTPUT_DIR=$interimDir/$SOURCE_TYPE/$year/$month/$day
      mkdir -p $GEN_OUTPUT_DIR
      /usr/src/app/genscript/genparquet.py --storesitename --codec gzip
      
      # exo2algae
      export SOURCE_TYPE=$SOURCE_TYPE_2
      export GEN_YAML_CONF=$GEN_YAML_CONF_2
      export GEN_SCHEMA_FILE=$GEN_SCHEMA_FILE_2
      export GEN_OUTPUT_DIR=$interimDir/$SOURCE_TYPE/$year/$month/$day
      mkdir -p $GEN_OUTPUT_DIR
      /usr/src/app/genscript/genparquet.py --storesitename --codec gzip

      # exo2conductivity
      export SOURCE_TYPE=$SOURCE_TYPE_3
      export GEN_YAML_CONF=$GEN_YAML_CONF_3
      export GEN_SCHEMA_FILE=$GEN_SCHEMA_FILE_3
      export GEN_OUTPUT_DIR=$interimDir/$SOURCE_TYPE/$year/$month/$day
      mkdir -p $GEN_OUTPUT_DIR
      /usr/src/app/genscript/genparquet.py --storesitename --codec gzip

      # exo2dissolvedoxygen
      export SOURCE_TYPE=$SOURCE_TYPE_4
      export GEN_YAML_CONF=$GEN_YAML_CONF_4
      export GEN_SCHEMA_FILE=$GEN_SCHEMA_FILE_4
      export GEN_OUTPUT_DIR=$interimDir/$SOURCE_TYPE/$year/$month/$day
      mkdir -p $GEN_OUTPUT_DIR
      /usr/src/app/genscript/genparquet.py --storesitename --codec gzip

      # exo2fdom
      export SOURCE_TYPE=$SOURCE_TYPE_5
      export GEN_YAML_CONF=$GEN_YAML_CONF_5
      export GEN_SCHEMA_FILE=$GEN_SCHEMA_FILE_5
      export GEN_OUTPUT_DIR=$interimDir/$SOURCE_TYPE/$year/$month/$day
      mkdir -p $GEN_OUTPUT_DIR
      /usr/src/app/genscript/genparquet.py --storesitename --codec gzip

      # exo2phorp
      export SOURCE_TYPE=$SOURCE_TYPE_6
      export GEN_YAML_CONF=$GEN_YAML_CONF_6
      export GEN_SCHEMA_FILE=$GEN_SCHEMA_FILE_6
      export GEN_OUTPUT_DIR=$interimDir/$SOURCE_TYPE/$year/$month/$day
      mkdir -p $GEN_OUTPUT_DIR
      /usr/src/app/genscript/genparquet.py --storesitename --codec gzip

      # exo2turbidity
      export SOURCE_TYPE=$SOURCE_TYPE_7
      export GEN_YAML_CONF=$GEN_YAML_CONF_7
      export GEN_SCHEMA_FILE=$GEN_SCHEMA_FILE_7
      export GEN_OUTPUT_DIR=$interimDir/$SOURCE_TYPE/$year/$month/$day
      mkdir -p $GEN_OUTPUT_DIR
      /usr/src/app/genscript/genparquet.py --storesitename --codec gzip

    done
    
    # Run second module - parquet_linkmerge (merges data from a source id that collected data from multiple sites in one day
    python3 -m parquet_linkmerge.parquet_linkmerge_main
    
    # Export L0 data to bucket
    if [[ -d "$OUT_PATH/$SOURCE_TYPE_1" || -d "$OUT_PATH/$SOURCE_TYPE_2" || -d "$OUT_PATH/$SOURCE_TYPE_3" || -d "$OUT_PATH/$SOURCE_TYPE_4" || -d "$OUT_PATH/$SOURCE_TYPE_5" || -d "$OUT_PATH/$SOURCE_TYPE_6" || -d "$OUT_PATH/$SOURCE_TYPE_7" ]]; then
      linkdir=$(mktemp -d)
      shopt -s globstar
      out_parquet_glob="${OUT_PATH}/**/*.parquet"
      # Example: /pfs/out/li191r/2023/01/01/12345/data/file.parquet
      echo "Linking output files to ${linkdir}"
      # set -x # Uncomment for troubleshooting
      for f in $out_parquet_glob; do
        # Parse the path
        [[ "$f" =~ ^$OUT_PATH/(.*)/([0-9]+)/([0-9]+)/([0-9]+)/(.*)/data/(.*)$ ]]
        fsourcetype="${BASH_REMATCH[1]}"
        fyear="${BASH_REMATCH[2]}"
        fmonth="${BASH_REMATCH[3]}"
        fday="${BASH_REMATCH[4]}"
        fsourceid="${BASH_REMATCH[5]}"
        fname="${BASH_REMATCH[6]}"
        outdir="${linkdir}/v2/${fsourcetype}/ms=${fyear}-${fmonth}/source_id=${fsourceid}"
        mkdir -p "${outdir}"
        ln -s "${f}" "${outdir}/${fname}"
      done

      echo "Syncing files to bucket"
      rclone \
        --no-check-dest \
        --copy-links \
        --gcs-bucket-policy-only \
        --gcs-no-check-bucket \
        --metadata-set "content-type=application/vnd.apache.parquet" \
        copy \
        "${linkdir}" \
        ":gcs://${BUCKET_NAME}"
        
      echo "Removing temporary files"
      rm -rf $linkdir
      
      # set +x # Uncomment for troubleshooting
    fi
    EOF
  env:
    # Environment variables for bash code
    SOURCE_TYPE_1: "exo2"
    SOURCE_TYPE_2: "exo2algae"
    SOURCE_TYPE_3: "exo2conductivity"
    SOURCE_TYPE_4: "exo2dissolvedoxygen"
    SOURCE_TYPE_5: "exo2fdom"
    SOURCE_TYPE_6: "exo2phorp"
    SOURCE_TYPE_7: "exo2turbidity"
    # Environment variables for data conversion step
    GEN_YAML_CONF_1: "/usr/src/app/genscript/configs/exo2_streams.yaml"
    GEN_SCHEMA_FILE_1: "/usr/src/app/schemas/exo2/exo2.avsc"
    GEN_YAML_CONF_2: "/usr/src/app/genscript/configs/exo2algae_streams.yaml"
    GEN_SCHEMA_FILE_2: "/usr/src/app/schemas/exo2algae/exo2algae.avsc"
    GEN_YAML_CONF_3: "/usr/src/app/genscript/configs/exo2conductivity_streams.yaml"
    GEN_SCHEMA_FILE_3: "/usr/src/app/schemas/exo2conductivity/exo2conductivity.avsc"
    GEN_YAML_CONF_4: "/usr/src/app/genscript/configs/exo2dissolvedoxygen_streams.yaml"
    GEN_SCHEMA_FILE_4: "/usr/src/app/schemas/exo2dissolvedoxygen/exo2dissolvedoxygen.avsc"
    GEN_YAML_CONF_5: "/usr/src/app/genscript/configs/exo2fdom_streams.yaml"
    GEN_SCHEMA_FILE_5: "/usr/src/app/schemas/exo2fdom/exo2fdom.avsc"
    GEN_YAML_CONF_6: "/usr/src/app/genscript/configs/exo2phorp_streams.yaml"
    GEN_SCHEMA_FILE_6: "/usr/src/app/schemas/exo2phorp/exo2phorp.avsc"
    GEN_YAML_CONF_7: "/usr/src/app/genscript/configs/exo2turbidity_streams.yaml"
    GEN_SCHEMA_FILE_7: "/usr/src/app/schemas/exo2turbidity/exo2turbidity.avsc"
    LOG_LEVEL: INFO
    REQUESTS_CA_BUNDLE: "/etc/pki/tls/cert.pem"
    # Environment variables for linkmerge step
    IN_PATH: /tmp/interimData
    OUT_PATH: /pfs/out
    SOURCE_TYPE_INDEX: '3'
    YEAR_INDEX: '4'
    MONTH_INDEX: '5'
    DAY_INDEX: '6'
    SOURCE_ID_INDEX: '7'
    KAFKA_RETENTION_DAYS: "15"
  secrets:
  - name: pachd-trino-secret
    key: TRINO_HOST
    env_var: PRESTO_HOST
  - name: pachd-trino-secret
    key: TRINO_PASSWORD
    env_var: PRESTO_PASSWORD
  - name: pachd-trino-secret
    key: TRINO_USER
    env_var: PRESTO_USER
  - name: l0-bucket
    env_var: BUCKET_NAME
    key: LO_BUCKET
input:
  pfs:
    name: import_trigger
    repo: exo2_cron_daily_and_date_control
    glob: "/exo2/*/*/*"
output_branch: master
parallelism_spec:
  constant: 3
autoscaling: true
resource_requests:
  memory: 300M
  cpu: 1.3
resource_limits:
  memory: 1G
  cpu: 2
sidecar_resource_requests:
  memory: 2G
  cpu: 0.5
sidecar_resource_limits:
  memory: 3G
  cpu: 1.2
datum_set_spec:
  number: 1
scheduling_spec:
  node_selector:
    cloud.google.com/compute-class: pach-pipeline-class
