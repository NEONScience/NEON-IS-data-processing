---
pipeline:
  name: li191r_calibration_group_and_convert
transform:
  image_pull_secrets: [battelleecology-quay-read-all-pull-secret]
<<<<<<< HEAD
  image: quay.io/battelleecology/neon-is-cal-grp-conv:82a259b6056253a7effdb0d07d2c5c06c02e9ff0
=======
  image: quay.io/battelleecology/neon-is-cal-grp-conv:d8b7e78d98bc53f183c6c6cc0635da393dcd7810
>>>>>>> master
  cmd: ["/bin/bash"]
  stdin:
  - "#!/bin/bash"
  - '# Refresh interim directories with each datum (otherwise they persist and cause probs)'
  - rm -r -f /data/*
  - mkdir -p /data/kafka_merged # Filter joiner relies on the same path positions among inputs (i.e. repo name in 2nd position)
  - mkdir -p /data/pfs/filter_joined # R modules must have pfs in the repo structure
  - '# Detect if we have data coming from Kafka or trino'
  - if [ ${KAFKA_UNMERGED_DATA+x} ]; then 
  - '# Data from kafka. '
  - '# Run kafka combiner'
  - Rscript ./flow.kfka.comb.R
        DirIn=$KAFKA_UNMERGED_DATA
        DirOut=/data/kafka_merged
        DirErr=/pfs/out/errored_datums
        FileSchmL0=$FILE_SCHEMA_L0
  - '# Set CONFIG for filter-joiner to the kafka version and run filter joiner'
  - export CONFIG=$CONFIG_KAFKA
  - python3 -m filter_joiner.filter_joiner_main
  - elif [ ${DATA_PATH_TRINO+x} ]; then 
  - '# Data from trino. '
  - '# Set CONFIG for filter-joiner to the trino version and run filter joiner'
  - export CONFIG=$CONFIG_TRINO
  - python3 -m filter_joiner.filter_joiner_main
  - else echo "FATAL - Input repository names do not match expectations. Check pipeline specification."
  - fi  
  - '# Run calibration conversion module'
  - Rscript ./flow.cal.conv.R 
      DirIn=/data/pfs/filter_joined
      DirOut=/pfs/out
      DirErr=/pfs/out/errored_datums 
      FileSchmData=$FILE_SCHEMA_DATA
      FileSchmQf=$FILE_SCHEMA_FLAGS
      TermFuncConv=voltage:def.cal.conv.poly
      TermQf=voltage
      TermFuncUcrt=voltage:def.ucrt.meas.mult,def.ucrt.fdas.volt.poly
      FileUcrtFdas=$FILE_UNCERTAINTY_FDAS
  env:
    # Environment variables for filter-joiner.
    # There are two configs here, CONFIG_KAFKA is when data comes from kafka, CONFIG_TRINO is when data comes from trino. 
    # The engironment variable CONFIG is set to the appropriate one as detected in the bash script above
    CONFIG_KAFKA: |
      ---
      # Configuration for filter-joiner module that will bring together the data and calibrations
      # In Pachyderm root will be index 0, 'pfs' index 1, and the repo name index 2.
      # Metadata indices will typically begin at index 3.
      input_paths:
        - path:
            name: DATA_PATH_KAFKA
            # Filter for data directory
            glob_pattern: /data/kafka_merged/li191r/*/*/*/*/**
            # Join on named location (already joined below by day)
            join_indices: [7]
            outer_join: true
        - path:
            name: CALIBRATION_PATH
            # Filter for data directory
            glob_pattern: /pfs/CALIBRATION_PATH/li191r/*/*/*/*/**
            # Join on named location (already joined below by day)
            join_indices: [7]
    CONFIG_TRINO: |
      ---
      # Configuration for filter-joiner module that will bring together the data and calibrations
      # In Pachyderm root will be index 0, 'pfs' index 1, and the repo name index 2.
      # Metadata indices will typically begin at index 3.
      input_paths:
        - path:
            name: DATA_PATH_TRINO
            # Filter for data directory
            glob_pattern: /pfs/DATA_PATH_TRINO/li191r/*/*/*/*/**
            # Join on named location (already joined below by day)
            join_indices: [7]
            outer_join: true
        - path:
            name: CALIBRATION_PATH
            # Filter for data directory
            glob_pattern: /pfs/CALIBRATION_PATH/li191r/*/*/*/*/**
            # Join on named location (already joined below by day)
            join_indices: [7]
    OUT_PATH: /data/pfs/filter_joined
    LOG_LEVEL: INFO
    RELATIVE_PATH_INDEX: "3" # Must be consistent across inputs 
    LINK_TYPE: COPY # options are COPY or SYMLINK. MUST BE SIMLINK IF USING COMBINED MODULE.
    # Environment variables for calibration module
    PARALLELIZATION_INTERNAL: '1' # Option for calibration conversion module
input:
  cross:
  - pfs:
      name: FILE_SCHEMA_L0
      repo: li191r_avro_schemas
      glob: /li191r/li191r.avsc
  - pfs:
      name: FILE_SCHEMA_DATA
      repo: li191r_avro_schemas
      glob: /li191r/li191r_calibrated.avsc
  - pfs:
      name: FILE_SCHEMA_FLAGS
      repo: li191r_avro_schemas
      glob: /li191r/flags_calibration_li191r.avsc
  - pfs:
      name: FILE_UNCERTAINTY_FDAS
      repo: li191r_uncertainty_fdas
      glob: /fdas_calibration_uncertainty_general.json
  # Need to send in the joined calibrations first with the trino data then with the kafka data in order for the filter-joiner to correctly join the calibrations
  - union:
    - join:
      - pfs:
          name: DATA_PATH_TRINO
          repo: li191r_data_source_trino
          glob: /li191r/(*)/(*)/(*)
          joinOn: $1/$2/$3
          outer_join: true
          empty_files: false # Make sure to use false if LINK_TYPE=COPY. Can also be set to false for LINK_TYPE=SYMLINK.
      - pfs:
          name: CALIBRATION_PATH
          repo: li191r_calibration_assignment
          glob: /li191r/(*)/(*)/(*)
          joinOn: $1/$2/$3
          empty_files: false # Make sure to use false if LINK_TYPE=COPY. Can also be set to false for LINK_TYPE=SYMLINK.
    - join:
      - pfs:
          name: KAFKA_UNMERGED_DATA
          repo: li191r_data_source_kafka
          glob: /li191r/(*)/(*)/(*)
          joinOn: $1/$2/$3
          outer_join: true
          empty_files: false # Make sure to use false if LINK_TYPE=COPY. Can also be set to false for LINK_TYPE=SYMLINK.
      - pfs:
          name: CALIBRATION_PATH
          repo: li191r_calibration_assignment
          glob: /li191r/(*)/(*)/(*)
          joinOn: $1/$2/$3
          empty_files: false # Make sure to use false if LINK_TYPE=COPY. Can also be set to false for LINK_TYPE=SYMLINK.
parallelism_spec:
  constant: 2
resource_requests:
  memory: 500M
  cpu: 1.2
autoscaling: true
scheduling_spec:
  node_selector:
    cloud.google.com/gke-ephemeral-storage-local-ssd: "true"
    nodepool.neonscience.org/pipeline: "yes"
    cloud.google.com/gke-spot: "true"
pod_spec: |-
  { "tolerations": [
    {
      "key": "nodepool.neonscience.org/pipeline",
      "operator": "Exists"
    },
    {
      "effect": "NoSchedule",
      "key": "cloud.google.com/gke-spot",
      "operator": "Exists"
    }  
  ] }
pod_patch: |-
  [
    { "op": "replace",
      "path":"/containers/1/resources/requests/memory",
      "value":"3.5G"
    },
    { "op": "replace",
      "path": "/containers/1/resources/requests/cpu",
      "value": "0.5"
    }
  ]
