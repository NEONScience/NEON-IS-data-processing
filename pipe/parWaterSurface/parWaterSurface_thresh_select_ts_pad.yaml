---
pipeline:
  name: parWaterSurface_thresh_select_ts_pad
transform:
  image_pull_secrets:
  - battelleecology-quay-read-all-pull-secret
  image: quay.io/battelleecology/neon-is-thsh-slct-ts-pad:d8b7e78d98bc53f183c6c6cc0635da393dcd7810
  cmd:
  - /bin/bash
  stdin:
  - "#!/bin/bash"
  - '# Refresh interim directories with each datum (otherwise they persist and cause probs)'
  - rm -r -f /usr/src/app/pfs/interimData
  - rm -r -f /usr/src/app/pfs/interimDataCopy
  - mkdir -p /usr/src/app/pfs/interimData
  - '# Run first module - threshold_select'
  - Rscript ./flow.thsh.slct.R 
      DirIn=$REPO_LOCATIONS
      DirOut=/usr/src/app/pfs/interimData
      DirErr=/pfs/out/errored_datums
      FileThsh=$FILE_THRESHOLDS
      "TermCtxt1=par|upward-facing"
      "DirSubCopy=location|data|uncertainty_data|flags"
  - '# Copy output to another interim folder to destroy links (cannot daisy chain links from pfs input to output)'
  - cp -rL /usr/src/app/pfs/interimData /usr/src/app/pfs/interimDataCopy 
  - rm -r -f /usr/src/app/pfs/interimData 
  - '# Run second module - timeseries_padder'
  - python3 -m timeseries_padder.timeseries_padder.variable_pad_main --yearindex 6 --monthindex 7 --dayindex 8 --locindex 11 --subdirindex 12
  - '# Final step - collapse the interim directory structure in /pfs/out'
  - cp -rL /pfs/out/app/pfs/interimDataCopy/* /pfs/out
  - rm -r /pfs/out/app
  env:
    DATA_PATH: /usr/src/app/pfs/interimDataCopy
    OUT_PATH: /pfs/out
    LOG_LEVEL: INFO
    PAD_DIR: data
    COPY_DIR: none # Can be multiple, separated by commas without spaces. Directories other than the pad directory and threshold directory to copy to the output (e.g. location,flags). Set to something like 'none' if none other are desired.
    RELATIVE_PATH_INDEX: '6'
output_branch: master
input:
  cross:
  - pfs:
      name: REPO_LOCATIONS
      repo: parWaterSurface_group_path
      glob: /*/*/*
  - pfs:
      name: FILE_THRESHOLDS
      repo: parWaterSurface_threshold
      glob: /thresholds.json
parallelism_spec:
  constant: 1
resource_requests:
  memory: 200M
  cpu: 1.5
autoscaling: true
scheduling_spec:
  node_selector:
    cloud.google.com/gke-ephemeral-storage-local-ssd: "true"
    nodepool.neonscience.org/pipeline: "yes"
    cloud.google.com/gke-spot: "true"
pod_spec: |-
  { "tolerations": [
    {
      "key": "nodepool.neonscience.org/pipeline",
      "operator": "Exists"
    },
    {
      "effect": "NoSchedule",
      "key": "cloud.google.com/gke-spot",
      "operator": "Exists"
    }  
  ] }
pod_patch: |-
  [
    { "op": "replace",
      "path":"/containers/1/resources/requests/memory",
      "value":"1G"
    },
    { "op": "replace",
      "path": "/containers/1/resources/requests/cpu",
      "value": "0.5"
    }
  ]
