---
pipeline:
  name: surfacewaterPhysical_analyze_pad_and_qaqc_plau
transform:
  image_pull_secrets:
  - battelleecology-quay-read-all-pull-secret
  image: quay.io/battelleecology/neon-is-ts-pad-anls-qaqc-plau:v1.0.2
  cmd:
  - /bin/bash
  stdin:
  - "#!/bin/bash"
  - '# Refresh interim directories with each datum (otherwise they persist and cause probs)'
  - rm -r -f /usr/src/app/pfs/interimData
  - rm -r -f /usr/src/app/pfs/interimDataCopy
  - mkdir -p /usr/src/app/pfs/interimData
  - '# '
  - '# Determine which source type we have'
  - if [ ${SCHEMA_FLAGS_AQUATROLL+x} ]
  - then export DATA_TYPE=aquatroll
  - elif [ ${SCHEMA_FLAGS_LEVELTROLL+x} ]
  - then export DATA_TYPE=leveltroll
  - else echo "FATAL - Input repository names do not match expectations. Check pipeline specification."
  - fi
  - echo "Data type detected = $DATA_TYPE"
  - '# '
  - '# Run first module - padded_timeseries_analyzer'
  - export DATA_PATH=/pfs/DATA_PATH # The env var set by pachyderm is the last datum in the group. Need the base parent.
  - python3 -m padded_timeseries_analyzer.padded_timeseries_analyzer.padded_timeseries_analyzer_main
  - '# Copy output to another interim folder to destroy links (cannot daisy chain links from pfs input to output)'
  - cp -rL /usr/src/app/pfs/interimData /usr/src/app/pfs/interimDataCopy
  - rm -r -f /usr/src/app/pfs/interimData
  - '# '
  - '# Run second module - qaqc plausibility'
  - '# Run aquatroll and leveltroll separately'
  - if [ $DATA_TYPE = 'aquatroll' ]
  - then 
      Rscript ./flow.qaqc.plau.R
        DirIn=/usr/src/app/pfs/interimDataCopy
        DirOut=/pfs/out
        DirErr=/pfs/out/errored_datums
        FileSchmQf=$SCHEMA_FLAGS_AQUATROLL
        "TermTest1=pressure:null|gap|range|step|spike|persistence"
        "TermTest2=temperature:null|gap|range|step|spike|persistence"
        "TermTest3=conductivity:null|gap|range|step|spike|persistence"
        DirSubCopy=location
  - elif [ $DATA_TYPE = 'leveltroll' ]
  - then 
      Rscript ./flow.qaqc.plau.R
        DirIn=/usr/src/app/pfs/interimDataCopy
        DirOut=/pfs/out
        DirErr=/pfs/out/errored_datums
        FileSchmQf=$SCHEMA_FLAGS_LEVELTROLL
        "TermTest1=pressure:null|gap|range|step|spike|persistence"
        "TermTest2=temperature:null|gap|range|step|spike|persistence"
        DirSubCopy=location
  - else echo "FATAL - Cannot determine source_type as aquatroll or leveltroll. Aborting..."
  - fi
  env:
    # Environment variables for padded timeseries analyzer
    OUT_PATH: /usr/src/app/pfs/interimData
    LOG_LEVEL: INFO
    RELATIVE_PATH_INDEX: '3'
    PARALLELIZATION_INTERNAL: '4'
input:
# We're going to send in the aquatroll locations separately from the leveltroll locations
# The 'separate' part is achieved by the union. Each datum in a union is sent in separately to the container. 
# Each datum consists of a cross between the aquatroll or leveltroll data and it's associated avro schema 
# for the output. The group nested within this cross is what allows us to send in all the aquatroll data for 
# each day in as one datum. It groups by day AND sensor type.
# We need to do some distinguishing between these sensor types when we execute the code above. We'll 
# determine which sensor type we have by seeing which SCHEMA_FLAGS_[SOURCE_TYPE] environment variables is populated 
# in the container. 
  union:
  - cross:
    - pfs:
       name: SCHEMA_FLAGS_AQUATROLL
       repo: surfacewaterPhysical_avro_schemas
       glob: /surfacewaterPhysical/flags_plausibility_surfacewaterPhysical_aquatroll200.avsc
    - group:
      - pfs:
          name: DATA_PATH
          repo: surfacewaterPhysical_thresh_select_ts_pad
          glob: /(*/*/*)/*/(aquatroll200)
          group_by: "$1$2"
  - cross:
    - pfs:
       name: SCHEMA_FLAGS_LEVELTROLL
       repo: surfacewaterPhysical_avro_schemas
       glob: /surfacewaterPhysical/flags_plausibility_surfacewaterPhysical_leveltroll500.avsc
    - group:
      - pfs:
          name: DATA_PATH
          repo: surfacewaterPhysical_thresh_select_ts_pad
          glob: /(*/*/*)/*/(leveltroll500)
          group_by: "$1$2"
parallelism_spec:
  constant: 5
resource_requests:
  memory: 2.5G
  cpu: 4.3
autoscaling: true
scheduling_spec:
  node_selector:
    cloud.google.com/gke-ephemeral-storage-local-ssd: "true"
    nodepool.neonscience.org/pipeline: "yes"
    cloud.google.com/gke-spot: "true"
pod_spec: |-
  { "tolerations": [
    {
      "key": "nodepool.neonscience.org/pipeline",
      "operator": "Exists"
    },
    {
      "effect": "NoSchedule",
      "key": "cloud.google.com/gke-spot",
      "operator": "Exists"
    }  
  ] }
pod_patch: |-
  [
    { "op": "replace",
      "path":"/containers/1/resources/requests/memory",
      "value":"1G"
    },
    { "op": "replace",
      "path": "/containers/1/resources/requests/cpu",
      "value": "0.5"
    }
  ]
  
